{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d8e539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Célula 1 executada: Bibliotecas importadas e CAMINHOS CORRIGIDOS.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.morphology import remove_small_objects, binary_opening, disk\n",
    "from skimage.measure import label, regionprops\n",
    "from scipy.ndimage import binary_fill_holes, distance_transform_edt\n",
    "from skimage.filters import threshold_otsu, gaussian\n",
    "from skimage.exposure import rescale_intensity, equalize_adapthist\n",
    "\n",
    "# --- Variáveis Globais (do segmentation.ipynb) ---\n",
    "\n",
    "# Caminho para o diretório de dados\n",
    "DATA_DIR = '../database/axl/'\n",
    "CSV_PATH = '../database/oasis_longitudinal_demographic.csv'\n",
    "\n",
    "# Parâmetros de segmentação\n",
    "N_CLUSTERS = 4\n",
    "MIN_AREA_VENTRICLE = 100\n",
    "MAX_AREA_VENTRICLE = 15000\n",
    "MIN_AREA_BRAIN = 5000\n",
    "\n",
    "# Seed para reprodutibilidade\n",
    "random.seed(64)\n",
    "\n",
    "print(\"Célula 1 executada: Bibliotecas importadas e CAMINHOS CORRIGIDOS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c07ce3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Célula 2 executada: Função 'segmentar_ventriculos' definida.\n"
     ]
    }
   ],
   "source": [
    "def segmentar_ventriculos(image_slice, n_clusters, min_area_brain, min_area_ventricle, max_area_ventricle):\n",
    "    \"\"\"\n",
    "    Segmenta os ventrículos cerebrais usando a lógica robusta \n",
    "    (CLAHE, Skull Stripping, K-Means + Filtro de Área).\n",
    "    \"\"\"\n",
    "    shape = image_slice.shape\n",
    "    \n",
    "    # 1. Pré-processamento\n",
    "    img_norm = rescale_intensity(image_slice, out_range=(0, 1))\n",
    "    img_clahe = equalize_adapthist(img_norm)\n",
    "    img_smooth = gaussian(img_clahe, sigma=1)\n",
    "\n",
    "    # 2. Remoção do Crânio\n",
    "    t = threshold_otsu(img_smooth)\n",
    "    mask_cerebro = img_smooth > t\n",
    "    mask_cerebro = binary_opening(mask_cerebro, disk(3))\n",
    "    mask_cerebro = remove_small_objects(mask_cerebro, min_size=min_area_brain) \n",
    "    mask_cerebro = binary_fill_holes(mask_cerebro)\n",
    "    \n",
    "    labels_cerebro = label(mask_cerebro)\n",
    "    if labels_cerebro.max() == 0:\n",
    "        return np.zeros(shape, dtype=bool) # Retorna máscara vazia\n",
    "        \n",
    "    maior_comp_label = np.argmax([region.area for region in regionprops(labels_cerebro)]) + 1\n",
    "    mask_cerebro = (labels_cerebro == maior_comp_label)\n",
    "    img_sem_cranio = img_smooth * mask_cerebro\n",
    "\n",
    "    # 3. K-Means\n",
    "    pixels_cerebro = img_sem_cranio[mask_cerebro].reshape(-1, 1)\n",
    "    if pixels_cerebro.shape[0] < n_clusters:\n",
    "        return np.zeros(shape, dtype=bool)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=64, n_init=10).fit(pixels_cerebro)\n",
    "    centers = kmeans.cluster_centers_.flatten()\n",
    "    labels_flat = kmeans.labels_\n",
    "\n",
    "    # 4. Identificação do LCR\n",
    "    sorted_indices = np.argsort(centers)\n",
    "    indice_lcr = sorted_indices[0] \n",
    "    labels_kmeans = np.zeros(shape, dtype=int)\n",
    "    labels_kmeans[mask_cerebro] = labels_flat + 1\n",
    "    mask_lcr_total = (labels_kmeans == (indice_lcr + 1))\n",
    "\n",
    "    # 5. Isolamento dos Ventrículos (Filtro de Área)\n",
    "    labels_lcr = label(mask_lcr_total)\n",
    "    regioes_lcr = regionprops(labels_lcr)\n",
    "    mask_ventriculos_final = np.zeros(shape, dtype=bool)\n",
    "    \n",
    "    if not regioes_lcr:\n",
    "        return np.zeros(shape, dtype=bool)\n",
    "\n",
    "    for r in regioes_lcr:\n",
    "        if r.area > min_area_ventricle and r.area < max_area_ventricle:\n",
    "            mask_ventriculos_final[labels_lcr == r.label] = True\n",
    "\n",
    "    return binary_fill_holes(mask_ventriculos_final)\n",
    "\n",
    "print(\"Célula 2 executada: Função 'segmentar_ventriculos' definida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109f8c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Célula 3 executada: Função 'extrair_features' definida.\n"
     ]
    }
   ],
   "source": [
    "def extrair_features(ventricle_mask):\n",
    "    \"\"\"\n",
    "    Calcula os descritores de forma para a máscara dos ventrículos.\n",
    "    Lida com múltiplos componentes (ex: ventrículos laterais) somando\n",
    "    suas áreas e perímetros, e tirando médias ponderadas para \n",
    "    descritores de forma.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Se a máscara estiver vazia, retorna zero para todas as features\n",
    "    if np.sum(ventricle_mask) == 0:\n",
    "        return {\n",
    "            'Ventricle_Area': 0,\n",
    "            'Ventricle_Perimeter': 0,\n",
    "            'Ventricle_Circularity': 0,\n",
    "            'Ventricle_Eccentricity': 0,\n",
    "            'Ventricle_Solidity': 0,\n",
    "            'Ventricle_MajorAxisLength': 0\n",
    "        }\n",
    "\n",
    "    # Rotula os componentes (ex: ventrículo esquerdo e direito)\n",
    "    labels = label(ventricle_mask)\n",
    "    props = regionprops(labels)\n",
    "\n",
    "    # Inicializa variáveis\n",
    "    total_area = 0\n",
    "    total_perimeter = 0\n",
    "    \n",
    "    # Para médias ponderadas\n",
    "    weighted_ecc = 0\n",
    "    weighted_solidity = 0\n",
    "    weighted_major_axis = 0\n",
    "\n",
    "    for prop in props:\n",
    "        total_area += prop.area\n",
    "        total_perimeter += prop.perimeter\n",
    "        \n",
    "        # Pondera a feature pela área do componente\n",
    "        weighted_ecc += prop.eccentricity * prop.area\n",
    "        weighted_solidity += prop.solidity * prop.area\n",
    "        weighted_major_axis += prop.major_axis_length * prop.area\n",
    "\n",
    "    # Evita divisão por zero\n",
    "    if total_area == 0:\n",
    "        return { 'Ventricle_Area': 0, 'Ventricle_Perimeter': 0, 'Ventricle_Circularity': 0,\n",
    "                 'Ventricle_Eccentricity': 0, 'Ventricle_Solidity': 0, 'Ventricle_MajorAxisLength': 0 }\n",
    "\n",
    "    # Calcula a Circularidade (Form Factor): 4*pi*A / P^2\n",
    "    # (Evita divisão por zero se o perímetro for 0)\n",
    "    if total_perimeter == 0:\n",
    "        circularity = 0\n",
    "    else:\n",
    "        circularity = (4 * np.pi * total_area) / (total_perimeter ** 2)\n",
    "        \n",
    "    # Calcula as médias ponderadas\n",
    "    avg_ecc = weighted_ecc / total_area\n",
    "    avg_solidity = weighted_solidity / total_area\n",
    "    avg_major_axis = weighted_major_axis / total_area\n",
    "\n",
    "    return {\n",
    "        'Ventricle_Area': total_area,\n",
    "        'Ventricle_Perimeter': total_perimeter,\n",
    "        'Ventricle_Circularity': circularity,\n",
    "        'Ventricle_Eccentricity': avg_ecc,\n",
    "        'Ventricle_Solidity': avg_solidity,\n",
    "        'Ventricle_MajorAxisLength': avg_major_axis\n",
    "    }\n",
    "\n",
    "print(\"Célula 3 executada: Função 'extrair_features' definida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf8a22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando processamento em lote de todos os arquivos em ../database/axl/...\n",
      "Processado 50/373: OAS2_0070_MR3\n",
      "Processado 50/373: OAS2_0070_MR3\n",
      "Processado 100/373: OAS2_0108_MR2\n",
      "Processado 100/373: OAS2_0108_MR2\n",
      "Processado 150/373: OAS2_0140_MR2\n",
      "Processado 150/373: OAS2_0140_MR2\n",
      "Processado 200/373: OAS2_0068_MR2\n",
      "Processado 200/373: OAS2_0068_MR2\n",
      "Processado 250/373: OAS2_0080_MR3\n",
      "Processado 250/373: OAS2_0080_MR3\n",
      "Processado 300/373: OAS2_0020_MR3\n",
      "Processado 300/373: OAS2_0020_MR3\n",
      "Processado 350/373: OAS2_0078_MR3\n",
      "Processado 350/373: OAS2_0078_MR3\n",
      "Processado 373/373: OAS2_0161_MR2\n",
      "\n",
      "Processamento concluído. 373 imagens analisadas.\n",
      "\n",
      "Pré-visualização dos dados de features extraídos:\n",
      "   Ventricle_Area  Ventricle_Perimeter  Ventricle_Circularity  \\\n",
      "0          3140.0           503.493470               0.155651   \n",
      "1          3999.0           894.571681               0.062796   \n",
      "2          3733.0           706.139177               0.094078   \n",
      "3          4058.0           675.346284               0.111807   \n",
      "4          5227.0           502.156421               0.260486   \n",
      "\n",
      "   Ventricle_Eccentricity  Ventricle_Solidity  Ventricle_MajorAxisLength  \\\n",
      "0                0.601427            0.825846                  50.014538   \n",
      "1                0.938702            0.641442                  95.686624   \n",
      "2                0.941419            0.643551                 110.167346   \n",
      "3                0.932219            0.669293                 115.404328   \n",
      "4                0.760331            0.564288                 132.334638   \n",
      "\n",
      "          MRI ID  \n",
      "0  OAS2_0090_MR3  \n",
      "1  OAS2_0140_MR1  \n",
      "2  OAS2_0013_MR3  \n",
      "3  OAS2_0097_MR2  \n",
      "4  OAS2_0117_MR1  \n",
      "Processado 373/373: OAS2_0161_MR2\n",
      "\n",
      "Processamento concluído. 373 imagens analisadas.\n",
      "\n",
      "Pré-visualização dos dados de features extraídos:\n",
      "   Ventricle_Area  Ventricle_Perimeter  Ventricle_Circularity  \\\n",
      "0          3140.0           503.493470               0.155651   \n",
      "1          3999.0           894.571681               0.062796   \n",
      "2          3733.0           706.139177               0.094078   \n",
      "3          4058.0           675.346284               0.111807   \n",
      "4          5227.0           502.156421               0.260486   \n",
      "\n",
      "   Ventricle_Eccentricity  Ventricle_Solidity  Ventricle_MajorAxisLength  \\\n",
      "0                0.601427            0.825846                  50.014538   \n",
      "1                0.938702            0.641442                  95.686624   \n",
      "2                0.941419            0.643551                 110.167346   \n",
      "3                0.932219            0.669293                 115.404328   \n",
      "4                0.760331            0.564288                 132.334638   \n",
      "\n",
      "          MRI ID  \n",
      "0  OAS2_0090_MR3  \n",
      "1  OAS2_0140_MR1  \n",
      "2  OAS2_0013_MR3  \n",
      "3  OAS2_0097_MR2  \n",
      "4  OAS2_0117_MR1  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Iniciando processamento em lote de todos os arquivos em {DATA_DIR}...\")\n",
    "\n",
    "all_files = glob.glob(os.path.join(DATA_DIR, \"*.nii.gz\"))\n",
    "total_files = len(all_files)\n",
    "results_list = []\n",
    "\n",
    "for i, file_path in enumerate(all_files):\n",
    "    \n",
    "    # --- 1. Carregar Imagem ---\n",
    "    try:\n",
    "        # Extrai o nome base do arquivo, ex: \"OAS2_0090_MR3_axl\"\n",
    "        base_name = os.path.basename(file_path).split('.')[0]\n",
    "\n",
    "        # Remove o sufixo '_axl' E remove quaisquer espaços em branco\n",
    "        mr_id = base_name.replace('_axl', '').strip()\n",
    "        \n",
    "        nii_img = nib.load(file_path)\n",
    "        data = nii_img.get_fdata()\n",
    "        \n",
    "        if data.ndim == 3:\n",
    "            slice_z = data.shape[2] // 2\n",
    "            image_slice = data[:, :, slice_z]\n",
    "        elif data.ndim == 2:\n",
    "            image_slice = data\n",
    "        else:\n",
    "            print(f\"AVISO: Ignorando {mr_id} (dimensão {data.ndim}D).\")\n",
    "            continue\n",
    "            \n",
    "        # --- 2. Segmentar Ventrículos ---\n",
    "        ventricle_mask = segmentar_ventriculos(image_slice, \n",
    "                                               N_CLUSTERS, \n",
    "                                               MIN_AREA_BRAIN, \n",
    "                                               MIN_AREA_VENTRICLE,\n",
    "                                               MAX_AREA_VENTRICLE)\n",
    "        \n",
    "        # --- 3. Extrair Features ---\n",
    "        features = extrair_features(ventricle_mask)\n",
    "        \n",
    "        # --- 4. Salvar Resultado ---\n",
    "        features['MRI ID'] = mr_id # Agora 'mr_id' está limpo\n",
    "        results_list.append(features)\n",
    "        \n",
    "        if (i + 1) % 50 == 0 or (i + 1) == total_files:\n",
    "             print(f\"Processado {i + 1}/{total_files}: {mr_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao processar {base_name}: {e}\")\n",
    "\n",
    "print(f\"\\nProcessamento concluído. {len(results_list)} imagens analisadas.\")\n",
    "\n",
    "# Converter a lista de resultados em um DataFrame\n",
    "df_features = pd.DataFrame(results_list)\n",
    "\n",
    "# (Opcional, mas recomendado) Limpa a coluna de chave no df_features também\n",
    "if not df_features.empty:\n",
    "    df_features['MRI ID'] = df_features['MRI ID'].str.strip()\n",
    "\n",
    "print(\"\\nPré-visualização dos dados de features extraídos:\")\n",
    "print(df_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8254313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados demográficos para fusão...\n",
      "Fusão realizada com sucesso. Pré-visualização do DataFrame final:\n",
      "  Subject ID         MRI ID        Group  Visit  MR Delay M/F Hand  Age  EDUC  \\\n",
      "0  OAS2_0001  OAS2_0001_MR1  Nondemented      1         0   M    R   87    14   \n",
      "1  OAS2_0001  OAS2_0001_MR2  Nondemented      2       457   M    R   88    14   \n",
      "2  OAS2_0002  OAS2_0002_MR1     Demented      1         0   M    R   75    12   \n",
      "3  OAS2_0002  OAS2_0002_MR2     Demented      2       560   M    R   76    12   \n",
      "4  OAS2_0002  OAS2_0002_MR3     Demented      3      1895   M    R   80    12   \n",
      "\n",
      "   SES  ...  CDR  eTIV   nWBV    ASF  Ventricle_Area  Ventricle_Perimeter  \\\n",
      "0  2.0  ...  0.0  1987  0.696  0.883          4717.0           686.760497   \n",
      "1  2.0  ...  0.0  2004  0.681  0.876          4943.0           648.997041   \n",
      "2  NaN  ...  0.5  1678  0.736  1.046          4809.0           870.264069   \n",
      "3  NaN  ...  0.5  1738  0.713  1.010          4566.0           609.819372   \n",
      "4  NaN  ...  0.5  1698  0.701  1.034          5744.0           823.979797   \n",
      "\n",
      "   Ventricle_Circularity  Ventricle_Eccentricity  Ventricle_Solidity  \\\n",
      "0               0.125680                0.778735            0.476032   \n",
      "1               0.147474                0.776263            0.478880   \n",
      "2               0.079793                0.776428            0.502602   \n",
      "3               0.154292                0.793689            0.528488   \n",
      "4               0.106314                0.776788            0.565456   \n",
      "\n",
      "   Ventricle_MajorAxisLength  \n",
      "0                 143.076772  \n",
      "1                 145.603920  \n",
      "2                 117.960323  \n",
      "3                 127.950254  \n",
      "4                 123.596244  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "SUCESSO! 373 de 373 visitas/linhas foram mapeadas com features de imagem.\n"
     ]
    }
   ],
   "source": [
    "print(\"Carregando dados demográficos para fusão...\")\n",
    "\n",
    "try:\n",
    "    # Carregar o CSV\n",
    "    df_demographic = pd.read_csv(CSV_PATH, sep=';', decimal=',')\n",
    "    \n",
    "    if 'MRI ID' not in df_demographic.columns:\n",
    "         print(f\"ERRO: A coluna 'MRI ID' não foi encontrada em {CSV_PATH}\")\n",
    "    elif 'df_features' not in locals() or df_features.empty:\n",
    "         print(\"ERRO: O DataFrame 'df_features' está vazio. Execute a Célula 4 primeiro.\")\n",
    "    else:\n",
    "\n",
    "        # Limpa a coluna 'MRI ID' do CSV, removendo espaços em branco\n",
    "        df_demographic['MRI ID'] = df_demographic['MRI ID'].str.strip()\n",
    "        # (A coluna 'MRI ID' do df_features já foi limpa na Célula 4)\n",
    "        \n",
    "        # Funde os DataFrames\n",
    "        df_final = pd.merge(df_demographic, df_features, on='MRI ID', how='left')\n",
    "        \n",
    "        print(\"Fusão realizada com sucesso. Pré-visualização do DataFrame final:\")\n",
    "        print(df_final.head())\n",
    "        \n",
    "        # Verificar quantas imagens conseguimos mapear\n",
    "        mapeados = df_final['Ventricle_Area'].notna().sum()\n",
    "        total_visitas = len(df_final)\n",
    "        \n",
    "        # Esta é a verificação final:\n",
    "        if mapeados > 0:\n",
    "            print(f\"\\nSUCESSO! {mapeados} de {total_visitas} visitas/linhas foram mapeadas com features de imagem.\")\n",
    "        else:\n",
    "            print(f\"\\nFALHA NO MERGE. {mapeados} de {total_visitas} visitas/linhas foram mapeadas.\")\n",
    "            print(\"Verifique se os IDs realmente existem em ambos os datasets.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo demográfico não encontrado em {CSV_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERRO durante a fusão: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f83010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Planilhas finais salvas com sucesso:\n",
      "- Completa: ../database/features_full.csv\n",
      "- Identificadores + Features: ../database/features_identifiers.csv\n"
     ]
    }
   ],
   "source": [
    "if 'df_final' in locals():\n",
    "    output_path_full = '../database/features_full.csv'\n",
    "    output_path_identifiers = '../database/features_identifiers.csv'\n",
    "\n",
    "    # Salvar o DataFrame completo\n",
    "    df_final.to_csv(output_path_full, index=False, sep=';', decimal=',')\n",
    "\n",
    "    # Criar e salvar o DataFrame apenas com identificadores e features\n",
    "    identifier_columns = ['Subject ID', 'MRI ID', 'Group']\n",
    "    feature_columns = [col for col in df_final.columns if col not in identifier_columns]\n",
    "    df_identifiers = df_final[identifier_columns + feature_columns]\n",
    "    df_identifiers.to_csv(output_path_identifiers, index=False, sep=';', decimal=',')\n",
    "\n",
    "    print(f\"\\nPlanilhas finais salvas com sucesso:\\n- Completa: {output_path_full}\\n- Identificadores + Features: {output_path_identifiers}\")\n",
    "else:\n",
    "    print(\"\\nERRO: DataFrame 'df_final' não foi criado. As planilhas não foram salvas.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
