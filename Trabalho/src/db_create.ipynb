{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e247595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a78c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório de treino: ../database/treino\n",
      "Diretório de teste: ../database/teste\n",
      "Pastas ../database/treino/imgs e ../database/teste/imgs verificadas/criadas.\n"
     ]
    }
   ],
   "source": [
    "# --- Caminhos dos arquivos de entrada (baseado na estrutura do repositório) ---\n",
    "OASIS_CSV = '../database/oasis_longitudinal_demographic.csv'\n",
    "FEATURES_CSV = '../database/features_full.csv'\n",
    "IDENTIFIERS_CSV = '../database/features_identifiers.csv'\n",
    "\n",
    "# Assumindo que elas estão em uma pasta raiz, talvez baixadas separadamente.\n",
    "SOURCE_IMG_DIR = '../database/axl'\n",
    "\n",
    "# --- Caminhos de saída ---\n",
    "TREINO_DIR = '../database/treino'\n",
    "TESTE_DIR = '../database/teste'\n",
    "TREINO_IMG_DIR = os.path.join(TREINO_DIR, 'imgs')\n",
    "TESTE_IMG_DIR = os.path.join(TESTE_DIR, 'imgs')\n",
    "\n",
    "# --- Parâmetros da Divisão ---\n",
    "TEST_SIZE = 0.20\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"Diretório de treino: {TREINO_DIR}\")\n",
    "print(f\"Diretório de teste: {TESTE_DIR}\")\n",
    "\n",
    "os.makedirs(TREINO_IMG_DIR, exist_ok=True)\n",
    "os.makedirs(TESTE_IMG_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Pastas {TREINO_IMG_DIR} e {TESTE_IMG_DIR} verificadas/criadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f764828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma original df_oasis: (373, 15)\n",
      "Valores originais em 'Group': ['Nondemented' 'Demented' 'Converted']\n",
      "Tipo de dado da coluna CDR (deve ser float): float64\n",
      "Valores finais em 'Group': ['Demented' 'NonDemented']\n",
      "Forma final df_oasis: (183, 15)\n"
     ]
    }
   ],
   "source": [
    "# Carrega o dataframe principal\n",
    "try:\n",
    "    # Adicionado decimal=',' para ler corretamente os números (ex: 0,5) como floats\n",
    "    df_oasis = pd.read_csv(OASIS_CSV, sep=';', decimal=',')\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivo {OASIS_CSV} não encontrado.\")\n",
    "    # Se der erro aqui, pare ou trate\n",
    "    raise\n",
    "\n",
    "print(f\"Forma original df_oasis: {df_oasis.shape}\")\n",
    "print(f\"Valores originais em 'Group': {df_oasis['Group'].unique()}\")\n",
    "print(f\"Tipo de dado da coluna CDR (deve ser float): {df_oasis['CDR'].dtype}\")\n",
    "\n",
    "# Função para mapear 'Converted'\n",
    "def map_class(row):\n",
    "    if row['Group'] == 'Converted':\n",
    "        if row['CDR'] > 0:\n",
    "            return 'Demented'\n",
    "        else: # Inclui CDR = 0 e CDR = NaN (que falha no > 0 e cai aqui)\n",
    "            return 'NonDemented'\n",
    "    return row['Group'] # Retorna 'Demented' ou 'NonDemented'\n",
    "\n",
    "# Aplica a função para criar a classe final\n",
    "df_oasis['Group'] = df_oasis.apply(map_class, axis=1)\n",
    "\n",
    "# Filtra o dataframe para conter apenas as duas classes finais\n",
    "df_oasis = df_oasis[df_oasis['Group'].isin(['Demented', 'NonDemented'])].copy()\n",
    "\n",
    "print(f\"Valores finais em 'Group': {df_oasis['Group'].unique()}\")\n",
    "print(f\"Forma final df_oasis: {df_oasis.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c00b6a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de pacientes únicos para divisão: 78\n",
      "Contagem de pacientes por classe (para estratificação):\n",
      "Group_num\n",
      "1    78\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mapeia Demented=1, NonDemented=0\n",
    "df_oasis['Group_num'] = df_oasis['Group'].map({'Demented': 1, 'NonDemented': 0})\n",
    "\n",
    "# Agrupa por paciente (Subject ID) e pega o valor máximo (1 se Demented, 0 se NonDemented)\n",
    "patient_labels = df_oasis.groupby('Subject ID')['Group_num'].max()\n",
    "\n",
    "# Remove pacientes que possam ter tido apenas visitas com NaN (se houver)\n",
    "patient_labels = patient_labels.dropna()\n",
    "\n",
    "print(f\"Total de pacientes únicos para divisão: {len(patient_labels)}\")\n",
    "print(\"Contagem de pacientes por classe (para estratificação):\")\n",
    "print(patient_labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b04e2d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de pacientes de treino: 62\n",
      "Total de pacientes de teste: 16\n"
     ]
    }
   ],
   "source": [
    "# Obtém a lista de pacientes (índice) e os rótulos (valores)\n",
    "patient_ids = patient_labels.index\n",
    "labels = patient_labels.values\n",
    "\n",
    "# Divide os pacientes\n",
    "train_patients, test_patients, _, _ = train_test_split(\n",
    "    patient_ids,\n",
    "    labels,\n",
    "    test_size=TEST_SIZE,\n",
    "    stratify=labels,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Total de pacientes de treino: {len(train_patients)}\")\n",
    "print(f\"Total de pacientes de teste: {len(test_patients)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf9261e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'MRI ID' encontrado nos CSVs de features.\n",
      "Forma df_feat: (373, 21)\n",
      "Forma df_ids: (373, 9)\n",
      "\n",
      "Processando diretório: ../database/treino\n",
      "  Pacientes: 62, Exames (MRI IDs): 143\n",
      "  CSVs salvos com sucesso em ../database/treino\n",
      "\n",
      "Processando diretório: ../database/teste\n",
      "  Pacientes: 16, Exames (MRI IDs): 40\n",
      "  CSVs salvos com sucesso em ../database/teste\n",
      "\n",
      "--- Processamento de CSVs Concluído ---\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Adicionando decimal=',' aqui também por segurança, \n",
    "    # caso os arquivos de features também usem vírgula.\n",
    "    df_feat = pd.read_csv(FEATURES_CSV, sep=';', decimal=',')\n",
    "    df_ids = pd.read_csv(IDENTIFIERS_CSV, sep=';', decimal=',')\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivos {FEATURES_CSV} ou {IDENTIFIERS_CSV} não encontrados.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler CSVs de features: {e}\")\n",
    "    print(\"Verifique se o separador (sep=';') está correto para ambos os arquivos.\")\n",
    "    raise\n",
    "\n",
    "# --- CORREÇÃO ---\n",
    "# Verifica se 'MRI ID' (com 'I') está presente\n",
    "if 'MRI ID' not in df_feat.columns or 'MRI ID' not in df_ids.columns:\n",
    "    print(\"ALERTA: 'MRI ID' não encontrado em um dos dataframes de features.\")\n",
    "    print(\"O script pode falhar ou filtrar incorretamente.\")\n",
    "else:\n",
    "    print(\"'MRI ID' encontrado nos CSVs de features.\")\n",
    "# --- FIM DA CORREÇÃO ---\n",
    "\n",
    "\n",
    "print(f\"Forma df_feat: {df_feat.shape}\")\n",
    "print(f\"Forma df_ids: {df_ids.shape}\")\n",
    "\n",
    "def save_datasets(patient_list, output_dir_base):\n",
    "    \"\"\"\n",
    "    Filtra todos os 3 dataframes pela lista de pacientes e salva os CSVs no diretório de saída.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessando diretório: {output_dir_base}\")\n",
    "    \n",
    "    # 1. Filtrar df_oasis\n",
    "    df_oasis_set = df_oasis[df_oasis['Subject ID'].isin(patient_list)]\n",
    "    \n",
    "    # --- CORREÇÃO ---\n",
    "    # 2. Obter os MRI IDs (exames) únicos deste conjunto de pacientes\n",
    "    mr_ids_set = df_oasis_set['MRI ID'].unique()\n",
    "    # --- FIM DA CORREÇÃO ---\n",
    "    \n",
    "    print(f\"  Pacientes: {len(patient_list)}, Exames (MRI IDs): {len(mr_ids_set)}\")\n",
    "    \n",
    "    # --- CORREÇÃO ---\n",
    "    # 3. Filtrar df_ids e df_feat usando os MRI IDs\n",
    "    # Assumindo que 'MRI ID' existe em ambos, conforme verificação anterior\n",
    "    df_ids_set = df_ids[df_ids['MRI ID'].isin(mr_ids_set)]\n",
    "    df_feat_set = df_feat[df_feat['MRI ID'].isin(mr_ids_set)]\n",
    "    # --- FIM DA CORREÇÃO ---\n",
    "    \n",
    "    # 4. Salvar os CSVs\n",
    "    try:\n",
    "        # Salva com vírgula decimal para consistência\n",
    "        df_oasis_set.to_csv(os.path.join(output_dir_base, 'oasis_longitudinal_demographic.csv'), index=False, sep=';', decimal=',')\n",
    "        df_ids_set.to_csv(os.path.join(output_dir_base, 'features_identifiers.csv'), index=False, sep=';', decimal=',')\n",
    "        df_feat_set.to_csv(os.path.join(output_dir_base, 'features_full.csv'), index=False, sep=';', decimal=',')\n",
    "        print(f\"  CSVs salvos com sucesso em {output_dir_base}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Erro ao salvar CSVs em {output_dir_base}: {e}\")\n",
    "\n",
    "# Salvar conjuntos de Treino (80%)\n",
    "save_datasets(train_patients, TREINO_DIR)\n",
    "\n",
    "# Salvar conjuntos de Teste (20%)\n",
    "save_datasets(test_patients, TESTE_DIR)\n",
    "\n",
    "print(\"\\n--- Processamento de CSVs Concluído ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e951054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copiando imagens para: ../database/treino/imgs\n",
      "  Copiadas/Verificadas: 143 imagens.\n",
      "  Não encontradas: 0 imagens.\n",
      "\n",
      "Copiando imagens para: ../database/teste/imgs\n",
      "  Copiadas/Verificadas: 40 imagens.\n",
      "  Não encontradas: 0 imagens.\n",
      "\n",
      "--- Processamento de Imagens Concluído ---\n"
     ]
    }
   ],
   "source": [
    "def copy_image_files(patient_list, destination_img_dir):\n",
    "    \"\"\"\n",
    "    Encontra e copia os arquivos .nii/.nii.gz para o destino (treino/imgs ou teste/imgs).\n",
    "    \"\"\"\n",
    "    print(f\"\\nCopiando imagens para: {destination_img_dir}\")\n",
    "    \n",
    "    if not os.path.exists(SOURCE_IMG_DIR):\n",
    "        print(f\"  ALERTA: Diretório de origem das imagens não encontrado: {SOURCE_IMG_DIR}\")\n",
    "        print(\"  Nenhuma imagem será copiada. Ajuste a variável 'SOURCE_IMG_DIR'.\")\n",
    "        return\n",
    "\n",
    "    # Lista de todos os arquivos de imagem de origem\n",
    "    try:\n",
    "        source_files = [f for f in os.listdir(SOURCE_IMG_DIR) if f.endswith(('.nii', '.nii.gz'))]\n",
    "    except Exception as e:\n",
    "        print(f\"  Erro ao listar arquivos em {SOURCE_IMG_DIR}: {e}\")\n",
    "        return\n",
    "        \n",
    "    # --- CORREÇÃO ---\n",
    "    # Pega os MRI IDs do conjunto de pacientes\n",
    "    mr_ids_set = df_oasis[df_oasis['Subject ID'].isin(patient_list)]['MRI ID'].unique()\n",
    "    # --- FIM DA CORREÇÃO ---\n",
    "    \n",
    "    copied_count = 0\n",
    "    missing_count = 0\n",
    "    \n",
    "    # Itera sobre os MR IDs que precisamos\n",
    "    for mr_id in mr_ids_set:\n",
    "        found_file = None\n",
    "        # Procura o arquivo de origem que contém o MR ID\n",
    "        # (ex: 'OAS2_0001_MR1' deve estar no nome do arquivo)\n",
    "        for fname in source_files:\n",
    "            if mr_id in fname:\n",
    "                found_file = fname\n",
    "                break # Encontrou o arquivo para este MR ID\n",
    "        \n",
    "        if found_file:\n",
    "            source_path = os.path.join(SOURCE_IMG_DIR, found_file)\n",
    "            dest_path = os.path.join(destination_img_dir, found_file)\n",
    "            \n",
    "            if not os.path.exists(dest_path): # Evita copiar se já existir\n",
    "                try:\n",
    "                    shutil.copy(source_path, dest_path)\n",
    "                    copied_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"  Erro ao copiar {source_path}: {e}\")\n",
    "            else:\n",
    "                copied_count += 1 # Conta como 'copiado' se já estiver lá\n",
    "        else:\n",
    "            print(f\"  Aviso: Imagem para MRI ID {mr_id} não encontrada em {SOURCE_IMG_DIR}\")\n",
    "            missing_count += 1\n",
    "            \n",
    "    print(f\"  Copiadas/Verificadas: {copied_count} imagens.\")\n",
    "    print(f\"  Não encontradas: {missing_count} imagens.\")\n",
    "\n",
    "# Copiar imagens de TREINO\n",
    "copy_image_files(train_patients, TREINO_IMG_DIR)\n",
    "\n",
    "# Copiar imagens de TESTE\n",
    "copy_image_files(test_patients, TESTE_IMG_DIR)\n",
    "\n",
    "print(\"\\n--- Processamento de Imagens Concluído ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "775deca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divisão 80/20 (Treino/Teste) concluída.\n",
      "Verifique as pastas './database/treino' e './database/teste'.\n"
     ]
    }
   ],
   "source": [
    "print(\"Divisão 80/20 (Treino/Teste) concluída.\")\n",
    "print(\"Verifique as pastas './database/treino' e './database/teste'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
